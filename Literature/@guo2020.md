---
title: Accelerating Large-Scale Inference with Anisotropic Vector Quantization
authors: Ruiqi Guo, Philip Sun, Erik Lindgren, Quan Geng, David Simcha, Felix Chern, Sanjiv Kumar
year: 2020
DOI: 10.48550/arXiv.1908.10396
aliases:
  - Anisotropic QUIPS Paper
---

>[!Links]-
>URL: http://arxiv.org/abs/1908.10396
>PDF: [PDF](guo2020.pdf)
>Zotero: [Zotero-Link](zotero://select/items/@guo2020)

>[!ABSTRACT]-
>Quantization based techniques are the current state-of-the-art for scaling maximum inner product search to massive databases. Traditional approaches to quantization aim to minimize the reconstruction error of the database points. Based on the observation that for a given query, the database points that have the largest [[../PhD Studies/Inner Product/Inner Products|inner products]] are more relevant, we develop a family of anisotropic quantization loss functions. Under natural statistical assumptions, we show that quantization with these loss functions leads to a new variant of vector quantization that more greatly penalizes the parallel component of a datapoint's residual relative to its orthogonal component. The proposed approach achieves state-of-the-art results on the public benchmarks available at \url{ann-benchmarks.com}.

